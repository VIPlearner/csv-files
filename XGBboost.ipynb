{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VIPlearner/csv-files/blob/main/XGBboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49pVkq_yszzp",
        "outputId": "2f00c791-2c21-45eb-fa5d-39c84b317162"
      },
      "id": "49pVkq_yszzp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "81e4d5a3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, Normalizer, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV, train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "81e4d5a3"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2657112",
        "outputId": "7955568e-4136-4442-abd0-db77958fc508"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1221"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/VIPlearner/csv-files/main/Train.csv\", index_col=\"VehicleID\")\n",
        "df['Maker-Model'] = df['Maker'] + ' ' + df['Model']\n",
        "#dropping irrelevant features\n",
        "#df.drop(['Colour'], axis = 1, inplace = True)\n",
        "#df.drop(['Maker'], axis = 1, inplace = True)\n",
        "#df.drop(['Model'], axis = 1, inplace = True)\n",
        "# df.drop(['Location'], axis = 1, inplace = True)\n",
        "df.drop(['Distance'], axis = 1, inplace = True)\n",
        "df['Year'] = df['Year'].str.replace(',', '').astype(float)\n",
        "# df['Distance'] = df['Distance'].str.replace(',', '').astype(float)\n",
        "df['Location'] = df.Location.astype('category')\n",
        "df['Type'] = df.Type.astype('category')\n",
        "df['Maker'] = df.Maker.astype('category')\n",
        "df['Model'] = df.Model.astype('category')\n",
        "df['Colour'] = df.Colour.astype('category')\n",
        "df = df[~(np.isnan(df[\"Amount (Million Naira)\"]))]\n",
        "X = df.drop(['Amount (Million Naira)'], axis = 1)\n",
        "y = df['Amount (Million Naira)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.3,\n",
        "                                                   random_state = 42)\n",
        "len(df['Maker-Model'].unique())"
      ],
      "id": "d2657112"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yBCvE5dNg6mU"
      },
      "id": "yBCvE5dNg6mU",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c4dc671c"
      },
      "outputs": [],
      "source": [
        "#numeric_features = [\"Year\", \"Type\"]\n",
        "year_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"scaler\", MinMaxScaler())]\n",
        ")\n",
        "\n",
        "distance_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scaler\", MinMaxScaler())]\n",
        ")\n",
        "\n",
        "type_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))]\n",
        ")\n",
        "categorical_features = [\"Location\", \"Model\", 'Maker', 'Colour', ]\n",
        "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"year\", year_transformer, [\"Year\"]),\n",
        "        # (\"distance\", year_transformer, [\"Distance\"]),\n",
        "        (\"cat\", categorical_transformer, categorical_features),\n",
        "        (\"type_cat\", type_transformer, [\"Type\"]),  \n",
        "    ]\n",
        ")\n",
        "\n"
      ],
      "id": "c4dc671c"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5c598ae4"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(\n",
        "  steps=[(\"preprocessor\", preprocessor), (\"estimator\", XGBRegressor())]\n",
        ")\n",
        "\n"
      ],
      "id": "5c598ae4"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4d2c5b7e",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75c94887-4250-42a8-ad05-2b9e2fd7f205"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['memory', 'steps', 'verbose', 'preprocessor', 'estimator', 'preprocessor__n_jobs', 'preprocessor__remainder', 'preprocessor__sparse_threshold', 'preprocessor__transformer_weights', 'preprocessor__transformers', 'preprocessor__verbose', 'preprocessor__verbose_feature_names_out', 'preprocessor__year', 'preprocessor__cat', 'preprocessor__type_cat', 'preprocessor__year__memory', 'preprocessor__year__steps', 'preprocessor__year__verbose', 'preprocessor__year__imputer', 'preprocessor__year__scaler', 'preprocessor__year__imputer__add_indicator', 'preprocessor__year__imputer__copy', 'preprocessor__year__imputer__fill_value', 'preprocessor__year__imputer__missing_values', 'preprocessor__year__imputer__strategy', 'preprocessor__year__imputer__verbose', 'preprocessor__year__scaler__clip', 'preprocessor__year__scaler__copy', 'preprocessor__year__scaler__feature_range', 'preprocessor__cat__categories', 'preprocessor__cat__drop', 'preprocessor__cat__dtype', 'preprocessor__cat__handle_unknown', 'preprocessor__cat__sparse', 'preprocessor__type_cat__memory', 'preprocessor__type_cat__steps', 'preprocessor__type_cat__verbose', 'preprocessor__type_cat__imputer', 'preprocessor__type_cat__encoder', 'preprocessor__type_cat__imputer__add_indicator', 'preprocessor__type_cat__imputer__copy', 'preprocessor__type_cat__imputer__fill_value', 'preprocessor__type_cat__imputer__missing_values', 'preprocessor__type_cat__imputer__strategy', 'preprocessor__type_cat__imputer__verbose', 'preprocessor__type_cat__encoder__categories', 'preprocessor__type_cat__encoder__drop', 'preprocessor__type_cat__encoder__dtype', 'preprocessor__type_cat__encoder__handle_unknown', 'preprocessor__type_cat__encoder__sparse', 'estimator__base_score', 'estimator__booster', 'estimator__colsample_bylevel', 'estimator__colsample_bynode', 'estimator__colsample_bytree', 'estimator__gamma', 'estimator__importance_type', 'estimator__learning_rate', 'estimator__max_delta_step', 'estimator__max_depth', 'estimator__min_child_weight', 'estimator__missing', 'estimator__n_estimators', 'estimator__n_jobs', 'estimator__nthread', 'estimator__objective', 'estimator__random_state', 'estimator__reg_alpha', 'estimator__reg_lambda', 'estimator__scale_pos_weight', 'estimator__seed', 'estimator__silent', 'estimator__subsample', 'estimator__verbosity'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "pipeline.get_params().keys()"
      ],
      "id": "4d2c5b7e"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "531cc89d"
      },
      "outputs": [],
      "source": [
        "parameters = {#'estimator__alpha': [1],\n",
        "              #'estimator':[DecisionTreeRegressor()],\n",
        "              'estimator__max_depth': [3],\n",
        "              'estimator__learning_rate': [0.1],\n",
        "              'estimator__n_estimators': [3500],\n",
        "              'estimator__colsample_bytree': [1], \n",
        "}"
      ],
      "id": "531cc89d"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "13934869",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d6887f-ad28-49aa-81fa-ec254c275bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15:11:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[15:11:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[15:11:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=2,\n",
              "             estimator=Pipeline(steps=[('preprocessor',\n",
              "                                        ColumnTransformer(transformers=[('year',\n",
              "                                                                         Pipeline(steps=[('imputer',\n",
              "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
              "                                                                                         ('scaler',\n",
              "                                                                                          MinMaxScaler())]),\n",
              "                                                                         ['Year']),\n",
              "                                                                        ('cat',\n",
              "                                                                         OneHotEncoder(handle_unknown='ignore'),\n",
              "                                                                         ['Location',\n",
              "                                                                          'Model',\n",
              "                                                                          'Maker',\n",
              "                                                                          'Colour']),\n",
              "                                                                        ('type_cat',\n",
              "                                                                         Pipeline(steps=[('imputer',\n",
              "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
              "                                                                                         ('encoder',\n",
              "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                                         ['Type'])])),\n",
              "                                       ('estimator', XGBRegressor())]),\n",
              "             param_grid={'estimator__colsample_bytree': [1],\n",
              "                         'estimator__learning_rate': [0.1],\n",
              "                         'estimator__max_depth': [3],\n",
              "                         'estimator__n_estimators': [3500]})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "grid = GridSearchCV(pipeline, parameters, cv=2)\n",
        "\n",
        "grid.fit(X_train, y_train)  \n",
        " "
      ],
      "id": "13934869"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "2c87c43b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97156508-9ae4-4307-f700-ca8cee3aa081"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'estimator__colsample_bytree': 1,\n",
              " 'estimator__learning_rate': 0.1,\n",
              " 'estimator__max_depth': 3,\n",
              " 'estimator__n_estimators': 3500}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "grid.best_params_"
      ],
      "id": "2c87c43b"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "30a49d79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0addb97b-df98-470e-e21a-424db3a28ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model score: 0.791\n"
          ]
        }
      ],
      "source": [
        "print(\"model score: %.3f\" % grid.score(X_test, y_test))"
      ],
      "id": "30a49d79"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "w-I508ktSDmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d264322-ec31-4f4e-a10c-af817f94398a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.992615490521162\n"
          ]
        }
      ],
      "source": [
        "y_pred = grid.predict(X_test)\n",
        "errors = mean_squared_error(y_test, y_pred, squared = False) \n",
        "print(errors)"
      ],
      "id": "w-I508ktSDmh"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vklNCKe8TlPQ"
      },
      "outputs": [],
      "source": [
        "test_df=pd.read_csv(\"https://raw.githubusercontent.com/VIPlearner/csv-files/main/Test.csv\")\n",
        "test_df.head()\n",
        "# dropping irrelevant features\n",
        "#test_df.drop(['Colour'], axis = 1, inplace = True)\n",
        "#test_df.drop(['Maker'], axis = 1, inplace = True)\n",
        "#test_df.drop(['Model'], axis = 1, inplace = True)\n",
        "# test_df.drop(['Location'], axis = 1, inplace = True)\n",
        "test_df.drop(['Distance'], axis = 1, inplace = True)\n",
        "test_df['Year'] = test_df['Year'].str.replace(',', '').astype(float)\n",
        "# test_df['Distance'] = test_df['Distance'].str.replace(',', '').astype(float)\n",
        "test_df['Location'] = test_df.Location.astype('category')\n",
        "test_df['Type'] = test_df.Type.astype('category')\n",
        "test_df['Maker'] = test_df.Maker.astype('category')\n",
        "test_df['Model'] = test_df.Model.astype('category')\n",
        "test_df['Colour'] = test_df.Colour.astype('category')\n"
      ],
      "id": "vklNCKe8TlPQ"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZnzzelwbasF",
        "outputId": "fd78451f-77bf-4cfd-b8bd-6f769eecaf51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2061 entries, 0 to 2060\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype   \n",
            "---  ------     --------------  -----   \n",
            " 0   VehicleID  2061 non-null   object  \n",
            " 1   Location   2061 non-null   category\n",
            " 2   Maker      2061 non-null   category\n",
            " 3   Model      2061 non-null   category\n",
            " 4   Year       2059 non-null   float64 \n",
            " 5   Colour     2061 non-null   category\n",
            " 6   Type       2007 non-null   category\n",
            "dtypes: category(5), float64(1), object(1)\n",
            "memory usage: 67.5+ KB\n"
          ]
        }
      ],
      "source": [
        "test_df.info()"
      ],
      "id": "2ZnzzelwbasF"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "CAabNkyVbrMq"
      },
      "outputs": [],
      "source": [
        "test_y_pred = grid.predict(test_df)"
      ],
      "id": "CAabNkyVbrMq"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZkdrFkfcFYN",
        "outputId": "d880ad9c-1934-49c5-fc26-258e121112f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of      VehicleID  Amount (Million Naira)\n",
              "0     VHL18518                5.527450\n",
              "1     VHL17149                6.684699\n",
              "2     VHL10927                4.283613\n",
              "3     VHL12909                5.090156\n",
              "4     VHL12348                9.094832\n",
              "...        ...                     ...\n",
              "2056  VHL17903               21.746851\n",
              "2057  VHL14018                6.661018\n",
              "2058  VHL17473                7.765547\n",
              "2059  VHL11480                8.936239\n",
              "2060  VHL13881                3.729594\n",
              "\n",
              "[2061 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "test_pred_df = pd.DataFrame({'VehicleID' : test_df['VehicleID'], 'Amount (Million Naira)': test_y_pred})\n",
        "test_pred_df.head"
      ],
      "id": "oZkdrFkfcFYN"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "uMIO-R8OeXg_"
      },
      "outputs": [],
      "source": [
        "test_pred_df.to_csv('23.csv', encoding='utf-8', index=False)"
      ],
      "id": "uMIO-R8OeXg_"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "9LMqM267gSb9",
        "outputId": "3607892a-9389-43a0-f1c2-becbbfca9435"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c4006636-7664-4f8f-b862-2b2e981b6259\", \"23.csv\", 38412)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"23.csv\")"
      ],
      "id": "9LMqM267gSb9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hhiRGsJhIQL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66fbf0e0-d81c-45ca-b490-19136434d46e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "id": "_hhiRGsJhIQL"
    },
    {
      "cell_type": "code",
      "source": [
        "help(XGBRegressor())"
      ],
      "metadata": {
        "id": "VMMUwNJ4xnYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9d7269-47da-481d-f232-545c281dcb46"
      },
      "id": "VMMUwNJ4xnYq",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on XGBRegressor in module xgboost.sklearn object:\n",
            "\n",
            "class XGBRegressor(XGBModel, sklearn.base.RegressorMixin)\n",
            " |  XGBRegressor(max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:linear', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain', **kwargs)\n",
            " |  \n",
            " |  Implementation of the scikit-learn API for XGBoost regression.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  max_depth : int\n",
            " |      Maximum tree depth for base learners.\n",
            " |  learning_rate : float\n",
            " |      Boosting learning rate (xgb's \"eta\")\n",
            " |  n_estimators : int\n",
            " |      Number of trees to fit.\n",
            " |  verbosity : int\n",
            " |      The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
            " |  silent : boolean\n",
            " |      Whether to print messages while running boosting. Deprecated. Use verbosity instead.\n",
            " |  objective : string or callable\n",
            " |      Specify the learning task and the corresponding learning objective or\n",
            " |      a custom objective function to be used (see note below).\n",
            " |  booster: string\n",
            " |      Specify which booster to use: gbtree, gblinear or dart.\n",
            " |  nthread : int\n",
            " |      Number of parallel threads used to run xgboost.  (Deprecated, please use ``n_jobs``)\n",
            " |  n_jobs : int\n",
            " |      Number of parallel threads used to run xgboost.  (replaces ``nthread``)\n",
            " |  gamma : float\n",
            " |      Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
            " |  min_child_weight : int\n",
            " |      Minimum sum of instance weight(hessian) needed in a child.\n",
            " |  max_delta_step : int\n",
            " |      Maximum delta step we allow each tree's weight estimation to be.\n",
            " |  subsample : float\n",
            " |      Subsample ratio of the training instance.\n",
            " |  colsample_bytree : float\n",
            " |      Subsample ratio of columns when constructing each tree.\n",
            " |  colsample_bylevel : float\n",
            " |      Subsample ratio of columns for each level.\n",
            " |  colsample_bynode : float\n",
            " |      Subsample ratio of columns for each split.\n",
            " |  reg_alpha : float (xgb's alpha)\n",
            " |      L1 regularization term on weights\n",
            " |  reg_lambda : float (xgb's lambda)\n",
            " |      L2 regularization term on weights\n",
            " |  scale_pos_weight : float\n",
            " |      Balancing of positive and negative weights.\n",
            " |  base_score:\n",
            " |      The initial prediction score of all instances, global bias.\n",
            " |  seed : int\n",
            " |      Random number seed.  (Deprecated, please use random_state)\n",
            " |  random_state : int\n",
            " |      Random number seed.  (replaces seed)\n",
            " |  missing : float, optional\n",
            " |      Value in the data which needs to be present as a missing value. If\n",
            " |      None, defaults to np.nan.\n",
            " |  importance_type: string, default \"gain\"\n",
            " |      The feature importance type for the feature_importances_ property: either \"gain\",\n",
            " |      \"weight\", \"cover\", \"total_gain\" or \"total_cover\".\n",
            " |  \\*\\*kwargs : dict, optional\n",
            " |      Keyword arguments for XGBoost Booster object.  Full documentation of parameters can\n",
            " |      be found here: https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst.\n",
            " |      Attempting to set a parameter via the constructor args and \\*\\*kwargs dict simultaneously\n",
            " |      will result in a TypeError.\n",
            " |  \n",
            " |      .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
            " |  \n",
            " |          \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee that parameters\n",
            " |          passed via this argument will interact properly with scikit-learn.\n",
            " |  \n",
            " |  Note\n",
            " |  ----\n",
            " |  A custom objective function can be provided for the ``objective``\n",
            " |  parameter. In this case, it should have the signature\n",
            " |  ``objective(y_true, y_pred) -> grad, hess``:\n",
            " |  \n",
            " |  y_true: array_like of shape [n_samples]\n",
            " |      The target values\n",
            " |  y_pred: array_like of shape [n_samples]\n",
            " |      The predicted values\n",
            " |  \n",
            " |  grad: array_like of shape [n_samples]\n",
            " |      The value of the gradient for each sample point.\n",
            " |  hess: array_like of shape [n_samples]\n",
            " |      The value of the second derivative for each sample point\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      XGBRegressor\n",
            " |      XGBModel\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      sklearn.base.RegressorMixin\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods inherited from XGBModel:\n",
            " |  \n",
            " |  __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:linear', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain', **kwargs)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  apply(self, X, ntree_limit=0)\n",
            " |      Return the predicted leaf every tree for each sample.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array_like, shape=[n_samples, n_features]\n",
            " |          Input features matrix.\n",
            " |      \n",
            " |      ntree_limit : int\n",
            " |          Limit number of trees in the prediction; defaults to 0 (use all trees).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
            " |          For each datapoint x in X and for each tree, return the index of the\n",
            " |          leaf x ends up in. Leaves are numbered within\n",
            " |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
            " |  \n",
            " |  evals_result(self)\n",
            " |      Return the evaluation results.\n",
            " |      \n",
            " |      If **eval_set** is passed to the `fit` function, you can call\n",
            " |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.\n",
            " |      When **eval_metric** is also passed to the `fit` function, the\n",
            " |      **evals_result** will contain the **eval_metrics** passed to the `fit` function.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      evals_result : dictionary\n",
            " |      \n",
            " |      Example\n",
            " |      -------\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          param_dist = {'objective':'binary:logistic', 'n_estimators':2}\n",
            " |      \n",
            " |          clf = xgb.XGBModel(**param_dist)\n",
            " |      \n",
            " |          clf.fit(X_train, y_train,\n",
            " |                  eval_set=[(X_train, y_train), (X_test, y_test)],\n",
            " |                  eval_metric='logloss',\n",
            " |                  verbose=True)\n",
            " |      \n",
            " |          evals_result = clf.evals_result()\n",
            " |      \n",
            " |      The variable **evals_result** will contain:\n",
            " |      \n",
            " |      .. code-block:: python\n",
            " |      \n",
            " |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
            " |          'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None, eval_set=None, eval_metric=None, early_stopping_rounds=None, verbose=True, xgb_model=None, sample_weight_eval_set=None, callbacks=None)\n",
            " |      Fit the gradient boosting model\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array_like\n",
            " |          Feature matrix\n",
            " |      y : array_like\n",
            " |          Labels\n",
            " |      sample_weight : array_like\n",
            " |          instance weights\n",
            " |      eval_set : list, optional\n",
            " |          A list of (X, y) tuple pairs to use as a validation set for\n",
            " |          early-stopping\n",
            " |      sample_weight_eval_set : list, optional\n",
            " |          A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n",
            " |          instance weights on the i-th validation set.\n",
            " |      eval_metric : str, callable, optional\n",
            " |          If a str, should be a built-in evaluation metric to use. See\n",
            " |          doc/parameter.rst. If callable, a custom evaluation metric. The call\n",
            " |          signature is func(y_predicted, y_true) where y_true will be a\n",
            " |          DMatrix object such that you may need to call the get_label\n",
            " |          method. It must return a str, value pair where the str is a name\n",
            " |          for the evaluation and value is the value of the evaluation\n",
            " |          function. This objective is always minimized.\n",
            " |      early_stopping_rounds : int\n",
            " |          Activates early stopping. Validation error needs to decrease at\n",
            " |          least every <early_stopping_rounds> round(s) to continue training.\n",
            " |          Requires at least one item in evals.  If there's more than one,\n",
            " |          will use the last. Returns the model from the last iteration\n",
            " |          (not the best one). If early stopping occurs, the model will\n",
            " |          have three additional fields: bst.best_score, bst.best_iteration\n",
            " |          and bst.best_ntree_limit.\n",
            " |          (Use bst.best_ntree_limit to get the correct value if num_parallel_tree\n",
            " |          and/or num_class appears in the parameters)\n",
            " |      verbose : bool\n",
            " |          If `verbose` and an evaluation set is used, writes the evaluation\n",
            " |          metric measured on the validation set to stderr.\n",
            " |      xgb_model : str\n",
            " |          file name of stored xgb model or 'Booster' instance Xgb model to be\n",
            " |          loaded before training (allows training continuation).\n",
            " |      callbacks : list of callback functions\n",
            " |          List of callback functions that are applied at end of each iteration.\n",
            " |          It is possible to use predefined callbacks by using :ref:`callback_api`.\n",
            " |          Example:\n",
            " |      \n",
            " |          .. code-block:: python\n",
            " |      \n",
            " |              [xgb.callback.reset_learning_rate(custom_rates)]\n",
            " |  \n",
            " |  get_booster(self)\n",
            " |      Get the underlying xgboost Booster of this model.\n",
            " |      \n",
            " |      This will raise an exception when fit was not called\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      booster : a xgboost booster of underlying model\n",
            " |  \n",
            " |  get_num_boosting_rounds(self)\n",
            " |      Gets the number of xgboost boosting rounds.\n",
            " |  \n",
            " |  get_params(self, deep=False)\n",
            " |      Get parameters.\n",
            " |  \n",
            " |  get_xgb_params(self)\n",
            " |      Get xgboost type parameters.\n",
            " |  \n",
            " |  load_model(self, fname)\n",
            " |      Load the model from a file.\n",
            " |      \n",
            " |      The model is loaded from an XGBoost internal binary format which is\n",
            " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
            " |      the Python Booster object (such as feature names) will not be loaded.\n",
            " |      Label encodings (text labels to numeric labels) will be also lost.\n",
            " |      **If you are using only the Python interface, we recommend pickling the\n",
            " |      model object for best results.**\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      fname : string or a memory buffer\n",
            " |          Input file name or memory buffer(see also save_raw)\n",
            " |  \n",
            " |  predict(self, data, output_margin=False, ntree_limit=None, validate_features=True)\n",
            " |      Predict with `data`.\n",
            " |      \n",
            " |      .. note:: This function is not thread safe.\n",
            " |      \n",
            " |        For each booster object, predict can only be called from one thread.\n",
            " |        If you want to run prediction using multiple thread, call ``xgb.copy()`` to make copies\n",
            " |        of model object and then call ``predict()``.\n",
            " |      \n",
            " |      .. note:: Using ``predict()`` with DART booster\n",
            " |      \n",
            " |        If the booster object is DART type, ``predict()`` will perform dropouts, i.e. only\n",
            " |        some of the trees will be evaluated. This will produce incorrect results if ``data`` is\n",
            " |        not the training data. To obtain correct results on test sets, set ``ntree_limit`` to\n",
            " |        a nonzero value, e.g.\n",
            " |      \n",
            " |        .. code-block:: python\n",
            " |      \n",
            " |          preds = bst.predict(dtest, ntree_limit=num_round)\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      data : DMatrix\n",
            " |          The dmatrix storing the input.\n",
            " |      output_margin : bool\n",
            " |          Whether to output the raw untransformed margin value.\n",
            " |      ntree_limit : int\n",
            " |          Limit number of trees in the prediction; defaults to best_ntree_limit if defined\n",
            " |          (i.e. it has been trained with early stopping), otherwise 0 (use all trees).\n",
            " |      validate_features : bool\n",
            " |          When this is True, validate that the Booster's and data's feature_names are identical.\n",
            " |          Otherwise, it is assumed that the feature_names are the same.\n",
            " |      Returns\n",
            " |      -------\n",
            " |      prediction : numpy array\n",
            " |  \n",
            " |  save_model(self, fname)\n",
            " |      Save the model to a file.\n",
            " |      \n",
            " |      The model is saved in an XGBoost internal binary format which is\n",
            " |      universal among the various XGBoost interfaces. Auxiliary attributes of\n",
            " |      the Python Booster object (such as feature names) will not be loaded.\n",
            " |      Label encodings (text labels to numeric labels) will be also lost.\n",
            " |      **If you are using only the Python interface, we recommend pickling the\n",
            " |      model object for best results.**\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      fname : string\n",
            " |          Output file name\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      Modification of the sklearn method to allow unknown kwargs. This allows using\n",
            " |      the full range of xgboost parameters that are not defined as member variables\n",
            " |      in sklearn grid search.\n",
            " |      Returns\n",
            " |      -------\n",
            " |      self\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from XGBModel:\n",
            " |  \n",
            " |  coef_\n",
            " |      Coefficients property\n",
            " |      \n",
            " |      .. note:: Coefficients are defined only for linear learners\n",
            " |      \n",
            " |          Coefficients are only defined when the linear model is chosen as base\n",
            " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
            " |          as tree learners (`booster=gbtree`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      Feature importances property\n",
            " |      \n",
            " |      .. note:: Feature importance is defined only for tree boosters\n",
            " |      \n",
            " |          Feature importance is only defined when the decision tree model is chosen as base\n",
            " |          learner (`booster=gbtree`). It is not defined for other base learner types, such\n",
            " |          as linear learners (`booster=gblinear`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : array of shape ``[n_features]``\n",
            " |  \n",
            " |  intercept_\n",
            " |      Intercept (bias) property\n",
            " |      \n",
            " |      .. note:: Intercept is defined only for linear learners\n",
            " |      \n",
            " |          Intercept (bias) is only defined when the linear model is chosen as base\n",
            " |          learner (`booster=gblinear`). It is not defined for other base learner types, such\n",
            " |          as tree learners (`booster=gbtree`).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.RegressorMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the coefficient of determination of the prediction.\n",
            " |      \n",
            " |      The coefficient of determination :math:`R^2` is defined as\n",
            " |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
            " |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
            " |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
            " |      The best possible score is 1.0 and it can be negative (because the\n",
            " |      model can be arbitrarily worse). A constant model that always predicts\n",
            " |      the expected value of `y`, disregarding the input features, would get\n",
            " |      a :math:`R^2` score of 0.0.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples. For some estimators this may be a precomputed\n",
            " |          kernel matrix or a list of generic objects instead with shape\n",
            " |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
            " |          is the number of samples used in the fitting for the estimator.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True values for `X`.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          :math:`R^2` of ``self.predict(X)`` wrt. `y`.\n",
            " |      \n",
            " |      Notes\n",
            " |      -----\n",
            " |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
            " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
            " |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
            " |      This influences the ``score`` method of all the multioutput\n",
            " |      regressors (except for\n",
            " |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2COnZkgh_fiV"
      },
      "id": "2COnZkgh_fiV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "XGBboost.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}